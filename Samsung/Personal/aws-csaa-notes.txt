AWS Solutions Architect  

-------------------------------------------------------
   AWS Object Storage and CDN - S3, Glacier and Cloudfront
   -------------------------------------------------------

- secure, durable, highly-scalable OBJECT STORAGE
- easy to use with simple interface
- STORE and RETRIEVE any amount of data from anywhere
- the DATA is SPREAD across multiple devices and facilities
- OBJECT based i.e. allows you to UPLOAD FILES
- Files can be from 0 bytes to 5 TB
- There is UNLIMITED STORAGE
- Files are STORED in BUCKETS
- S3 is a UNIVERSAL namespace, that it, names must be UNIQUE
- https://s3-eu-west-1.amazonaws.com/acloudguru
- you will receive http 200 code if the upload was successful
- S3 supports TORRENT protocol
- object based consists of the following
key, value, versioning, metadata and subresources; access control lists and torrent


*** Data Consistency Model for S3 ***

- read after write consistency for PUTS of new Objects = you will be able to read the object immediately
- eventual consistency for OVERWRITE PUTS (updating) and DELETES= can take some time to propagate
- either you are going to GET the OLD or NEW data

*** S3 - The Basics ***

- Built for 99.99% availability for the S3 platform
- Amazon guarantees 99.999999999% durability for S3 information (11x9's)
- Tiered Storage Available
- Lifecycle Management
- Versioning
- Encryption
- Secure your data using ACCESS CONTROL LISTS and BUCKET POLICIES

*** S3 - Storage Tiers/Classes ***

- 1 S3 Standard 99.99% availability, 99.999999999 durability, stored REDUNDANTLY across multiple DEVICES in multiple FACILITIES and is
   desgined to SUSTAIN the LOSS of 2 facilities concurrently.
- 2 S3 - IA (INFREQUENTLY ACCESSED) for data that is accessed LESS FREQUENTLY, but requires RAPID ACCESS when needed. Lower fee than S3,
   but you are charged a retrieval fee - use case is yearly REPORT
- 3 S3 One Zone - For where you want a lower-cost option for infrequently accessed data, but do not require the multiple Availability Zone data resilience
- 4 S3 Intelligent  Tiering - Designed to optimize costs by automatically moving data to the most cost-effective access tier without performance impact or operational overhead.
- 5 S3 Glacier - is a secure, durable and low-cost storage class for data archiving. Retrieval times configurable from minutes to hours
- 6 S3 Glacier Deep Archive - is Amazon's  S3's lowest-cost storage class where a retrieval time of 12 hours is acceptable.


# not updated
- RRS (Reduced Redundancy Storage) - designed to provide 99.99% durability and 99.99% availability of OBJECTS over a given year - use case
   DATA that can be GENERATED again like thumbnail of photos


- 4 S3 - Intelligent Tiering - Designed to optimize costs by automatically moving data to the most cost-effective access tier, without performance impact or operation overhead.

- 5 S3 Glacier - is a secure, durable, and low-cost storage class for data archiving. You can reliable store any amount of data at costs that are competitive with or cheaper than on-premise. Retrieval time configurable from minute to hour

- 6 S3 Glacier Deep Archive - is Amazon S3's lowest-cost storage class where a retrieval time of 12 hours is acceptable

*** Exam tips for S3 Life Cycle ***
- Automates moving object between the different storage tiers
- Can be used in conjunction with versioning
- Can be applied to current versions and previous versions

*** Exam tips for S3 Cross Region Replication ***
- Versioning must be enabled on both the source and destination buckets
- Regions must be unique
- Files in an existing bucket are not replicated automatically
- All subsequent updated files will be replicated automatically
- Delete markers are not replicated.
- Deleting individual version or delete markers will not be replicated

*** Exam tips for CloudFront ***
- Edge Location - This is the location where content will be cached.
- Origin - This is the origin of all the files that the CDN will distribute. Can be an S3 bucket, EC2, ELB or Route53
- Distribution - This is the name that is given to the CDN which consists of a collection of Edge Location
- Web Distribution - Typically used for Websites
- RTMP - Used for Media Streaming
- Edge Location are not just READ only -- you can write to them too
- Objects are cached for the life of TTL(Time to live)
- You can clear/invalidate cached object but you will be charged


*** What is S3 Transfer Acceleration? ***

- Amazon S3 Transfer Acceleration enables FAST, EASY and SECURE transfers of files over long distance between end users and an S3 bucket.
   Transfer Acceleration TAKES ADVANTAGE of Amazon Cloudfront's globally distributed EDGE locations. As the data arrives at an edge location, data is routed to Amazon s3 over an optimized network path



*** Exam tips for S3 101 ***
- Remember that S3 is Object based. Operating system and database can not be installed
- Files can be from 0 bytes to 5 TB
- There is UNLIMITED storage
- Files are stored in BUCKETS
- S3 is a UNIVERSAL NAMESPACE, that is, names MUST be unique globally

Encryption In Transit is achieved by:
- SSL/TLS
Encryption at rest (Server side) is achieved by
- S3 Managed Keys - SSE - S3
- AWS Key Management Service, Managed Keys - SSE  - KMS
- Server Side Encryption With Customer Provided Keys - SSE - C
Client Side Encryption

Some Best Practices with AWS Organizations;
- Always enable multi factor authentication on root account
- Always use a strong and complex password on root account
- Paying account should be used for billing purpose only. Do not deploy resources into the paying account
- Enable/Disable AWS service using Service Control Polices (SCP) either on OU or individual accounts


*** Storage Gateway ***
- is a service that connects an on-premises software appliance with cloud based storage to provide seamless and secure integration between an organization's on-premise IT environment and AWS's storage infrastructure.

- software appliance is available for download as a VM image that you install on a host in your data center.

The three different types of Storage Gateway are as follows:
- File Gateway (NFS & SMB) - For flat files, stored directly on S3
- Volume Gateway (iSCSI) - linking data storage facilities
	- Stored Volumes - Entire dataset is stored on site and is asynchronously backed up to S3.
	- Cached Volumes - Entire dataset is stored on S3 and the most frequently accessed data is cached on site.
- Gateway Virtual Tape Library (VTL) - move tape-based backup and archiving workflows to the AWS cloud easily, while keeping the backup application in place


Athena and Macie

What is Athena - Interactive query service which enables you to analyze and query data located in S3 using standard SQL
- Serverless, nothing to provision, pay per query / per TB scanned
- No need to set up complex Extract / Transform / Load (ETL) processes
- Works directly with data stored in S3

Where can Athena Be Used for?
- Can be used to query log files stored in S3, e.g. ELB logs, S3 access logs etc
- Generate business reports on data stored in S3
- Analyze AWS cost and usage reports
- Run queries on click-stream data

What is Macie? - Security service which uses Machine Learning and NLP (Natural Language Processing) to discover, classify and protect sensitive data stored in S3
- Uses AI to recognize if your S3 contains sensitive data such PII
- Dashboards, reporting and alerts
- Works directly with data stored in S3
- Can also analyze Cloudtrail logs
- Greate for PCS-DSS and preventing ID theft


What is PII (Personally Identifiable Information)?
- Personal data used to establish an individuals identity
- This data can be exploited by criminals used in identity theft and financial fraud
- Home address, email address, SSN
- Passport number, driver's license number
- D.O.B, phone number, bank account, credit card number




   ------------------------------------------
       EC2 (ELASTIC COMPUTE CLOUD)
   ------------------------------------------


- EC2 (Elastic Compute Cloud) - is a web service that provides resizable compute capacity in the cloud

*** EC2 Options ***

1. On Demand - allow you to pay a fixed rate by the hour (or by the second) with no commitment

2. Reserved - provide you with a capacity reservation, and offer a significant discount on the hourly charge for an instance.
   1 to 3 years terms

3. Spot - enable you to bid pwhatever price you want for instance capacity,providing for even greater savings
   if your application have flexible start and end times

4. Dedicated Hosts - Physical EC2 server dedicated for your use. Dedicated Hosts can help you reduce costs
   by allowing you to use your existing server-bound software licenses


*** Instance  Types ***

D - Density
R - RAM
M - Main choice for general purpose
C - Compute
G - Graphics
I - IOPS (Input/Output Operation per Second)
F - FPGA (Field Programmable Gate Arrays)
T - cheap general purpose (think T2 Micro)
P - Graphics (Pics)
X - EXtreme Memory

- What is EBS - Amazon EBS allows you to create storage volumes and attach it to your Amazon EC2 instances.
   Once attached, you can create a file system on top of these volumes, run a database, or use them in
   any other way you would use a block device. Amazon EBS volumes are placed in a specific AZ where they
   are automatically replicated to protect you from the failure of single component.

*** EBS Volume Types ***

1. General Purpose SSD (GP2) -

2. Provisioned IOPS SSD (IO1) -

3. Throughput Optimized HDD (ST1) - old school and traditional Disk Drive
   - "FOR LARGE AMOUNT OF SEQUENTIAL DATA"
   - Big data
   - Data warehouses
   - Log processing
   -Cannot be a boot volume

4. Cold HDD (SC1) - Lowest Cost Storage for infrequently accessed workloads
   - sample use case is FILE SERVER
   - CANNOT BE A BOOT VOLUME

5. Magnetic (Standard) - Lowest cost per gigabyte of all EBS Volumes type that is BOOTABLE
   Magnetic volume are ideal for workloads where data is accessed infrequently, and
   applications where the lowest storage cost is important

*** ENI vs ENA vs EFA***
1. ENI - Elastic Network Interface - essentially a virtual network card
2. EN - Enhanced Networking - Uses single root I/O Virtualization (SR-IOV) to provide high-performance networking capabilities on supported instance types. ENA is a subset. Higher bandwidth, higher packet per second (PPS). No additional charge. Use it when you want good network performance.
3. . EFA - Elastic Fabric Adapter - A Network device that you can attach to your Amazon EC2 instance to accelerate High Performance Computing (HPC) and machine learning applications. Provides lower and more consistent latency and higher throughput than the TCP transport traditionally used in cloud-based HPC systems. EFA can use OS-bypass
Scenarios for Network Interface:
- Create a management network
- Use network and security appliance in your VPC
- Create dual-homed instances and workloads/roles on distinct subnets
- Create a low-budget, high availability solution

Depending on your instance type, enhanced networking can be enabled using:
- Elastic Network Adapter (ENA), which supports network speed of up to 100 Gbps for supported instance type. OR
- Intel 82599 Virtual Function (VF) interface, which supports network speed of up to 10 Gbps supported instance type. Used for older instance types.

In the exam you will be given different scenarios and you will be asked to choose whether you should use ENI, EN or EFA.
- ENI - For basic networking. Perhaps you need a separate management network to your production network or a separate logging network and you need this at a low cost. In this scenario use multiple ENIs for each network
- Enhanced Network - For when you need speeds between 10 Gbps and 100 Gbps. Anywhere you need reliable, high throughput.
- Elastic Fabric Adapter - For when you need to accelerate High Performance Computing (HPC) and machine learning applications or if you need to do an OS-bypass. If you see a scenario question mentioning HPC or ML and asking what network adaptor you want, choose EFA.

*** Exam Tips EC2 ***
- Know the differences between:
   - On Demand
   - Spot
   - Reserved
   - Dedicated Hosts

- Remember with spot instance;
   - If you terminate the instance, you pay for the hour
   - If AWS terminates the spot instance, you get the hour it was terminated for free

- EBS Consists of;
   - SSD, General Purpose - GPS2 (Up to 10,000 IOPS)
   - SSD, Provisioned IOPS - IO1 (More than 10,000 IOPS)
   - HDD, Throughput Optimized - ST1 - frequently accesed workloads
   - HDD, Cold - SC1 - less frequently accessed data
   - HDD, magenetic - Standard - cheap, infrequently accessed storage

- You cannot mount 1 EBS volume to multiple EC2 instances, instead use EFS

*** Lab Summary ***

- Termination Protection is turned off by default, you must turn it on

- On a EBS-backed instance, the default action is for the root EBS volume to be deleted
   when instance is terminated

- EBS Root Volumes of your DEFAULT AMI's cannot be encrypted. You can also use a third party tool (such as a bit locker)
   to encrypt the root volume or this can be done when creating AMI's in the AWS console or using the API

- Additonal volumes can be encrypted

*** Security Group Lab ***

- All Inbound traffic is blocked by default

- All Outbound traffic is allowed (stateful)

- Changes to Security Groups take effect immediately

- You can have any number of EC2 instance a security group

- You can have multiple security groups attached to EC2 instances

- Security Groups are "STATEFUL"
   = If you create an inbound rule allowing traffic in, that traffic is automatically allowed back out again

- You cannot block specific IP addresses using Security Groups, instead use Network Access Control Lists

- You can specify allow rules, but not deny

*** EBS Volume and Snapshot ***

- Volumes exist on EBS:
   Virtual Hard Disk
- Snapshots exist on S3
- Snapshots are point in time copies of volume
- Snapshots are incremental - this means that only the blocks that have changed since your last snapshot are
   moved to S3
- First snapshot take time to create

*** Snapshots of Root Device Volume ***

- To create a snapshot for Amazon EBS volume that serve as a root devices, you should stop the instance
   before taking the snapshot
- However you can take a snap while the instance is running
- You can create AMI's from both Volumes and Snapshots
- You can change EBS volume sizes on the fly, including changing the size and storage type
- Volumes will ALWAYS be in the same availability zone as the EC2 instance.
- To move an EC2 volume from one AZ/Region to another, take a snap or an image of it, then copy
   it to a new Az/Region

*** How to encrypt a root device volume ***
1. Create a Snapshot of the unencrypted root device volume
2. Create a copy of Snapshot and select the encrypt option
3. Create an AMI from the encrypted Snapshot
4. Use that AMI to launch new encrypted instances

*** Volumes vs Snapshots - Security ***

- Snapshots of encrypted volumes are encrypted automatically
- Volumes restored from encrypted snapshots are encrypted automatically
- You can share snapshots but only if they are unencrypted
   = These snapshots can be shared with other AWS account or made public

*** EBS vs Instance Store ***

- All AMIs are categorized as either backed by Amazon EBS or backed by Instance Store

- For EBS Volumes: The root device for an instance launched from the AMI is an Amazon
   EBS volume created an Amazon EBS snapshot

- For Instance Store Volumes: The root device for an instance launched from AMI is an instance
   store volume created from a template stored in Amazon S3

- Instance Store Volumes are sometimes called Ephemeral Storage

- Instance store volumes cannot be stopped. If the underlying host fails, you will lose your data.

- EBS backed instance can be stopped. You will not lose the data on this instance if it is stopped.

- You can reboot both, you will not lose your data.

- By default, both ROOT volumes will be deleted on termination, however with EBS volumes,
   you can tell AWS to keep the root device volume

*** Elastic Load Balancers ***

- Instances monitored by ELB are reported as;
   InService, or OutofService
- Health Checks check the instance health by talking to it

- Have their own DNS name. You are never given an IP address.

- Read the ELB FAQ for Classic Load Balancers

*** CloudWatch Lab Exam Tips ***

- Standard Monitoring = 5 minutes
- Detailed Monitoring = 1 minute

- What can I do with Cloudwatch?
   = Dashboard - Creates awesome dashboard to see what is happening with your AWS
       environment
   = Alarms - Allows you to set alarm that notify you when particular thresholds are hit
   = Events - Cloudwatch Events helps you to respond to state changes in your AWS
       resources
   = Log - Cloudwatch Logs helps you to aggregate, monitor and store logs

- Cloudwatch is for logging, monitoring resources and performance
- Cloudtrail is for auditing. monitor AWS environment such as API calls, creating users, roles and etv

*** EC2 Instance Metadata ***

# curl http://169.254.169.254/latest/meta-data/  =  view and access information about the EC2 instance

*** Auto Scaling ***

- monitors your applications and automatically adjusts capacity to maintain steady, predictable performance
   at the lowest possible cost.

*** Placement Group ***

- Cluster Placement Group - grouping of instances within a single AZ. Recommended for applications that need low network latency and high throughput
- Spread Placement Group - is a group of instances that are each placed on distinct underlying hardware. Recommended for application that have a small number of critical instances.
- Partitioned Placement Group - has logical segments called partition. Each partition within a placement group has its own set of racks. Each rack has its own network and power source. No two partition shares the same racks. Recommended for multiple instances HDFS, HBase and Cassandra
- 
- A Clustered Placement group CAN't SPAN multiple Availability Zone while the Spread and Partitioned group can

- The name you specify for a placement group must be unique within your AWS account

- Only certain types of instances can be launched in a placement group (Compute Optimized, GPU, Memory Optimized, Storage Optimized)

- AWS recommend homogenous(same) instances within clustered placement groups.

- You can't merge placement groups.

- You can't move an existing instance into a placement group. You can create an AMI from your existing instance, and then launch a new instance from the AMI into a placement group


# not updated

- A Placement group is a LOGICAL GROUPING OF INSTANCES within a SINGLE AVAILABILITY ZONE.
   Using placement group enables applications to participate in a low-latency, 10 Gbps
   network. Placement groups are recommended for applications that benefit from
   LOW NETWORK LATENCY and HIGH NETWORK THROUGHPUT or both.


- The NAME you specify for a placement group MUST BE UNIQUE within your AWS group.

- Only certain types of instances can be launched in a placement group (Compute Optimized, GPU, Memory Optimized, Storage Optimized)

- AWS recommend homegenous(SAME SIZE, FAMILY) instances within placement groups.

- You CAN'T MERGE placement groups

- You CAN't MOVE an existing instance into a placement group. You can create an AMI from your existing
   instance, and then launch a new instance from the AMI into a placement group

*** AWS WAF ***
- is a web application firewall that lets you monitor the HTTP and HTTPS requests that are forwarded to Amazon Cloudfront, an Application Load Balancer or API Gateway. Also, AWS WAF lets you control access to your content.

At its most basic level, AWS WAF allows 3 different behaviours:
1. Allow all requests except ones you specify
2. Block all requests except ones you specify
3. Count the requests that match the properties you specify

Exam Tips: You will be given different scenarios and you will be asked how to block malicious IP Address
- Use AWS WAF - protects from SQL injection, cross site scripting
- Use Network ACLs - block request based on port/service


*** ELASTIC FILE SYSTEM (EFS) ***

- Amazon Elastic File System is a FILE STORAGE for Amazon Elastic Compute Cloud instances. It is a easy to use
   and provides a simple interface that allows you to create and configure files systems quickly and easily.
   With EFS, storage capacity is ELASTIC, growing and shrinking automatically as you add and remove files,
   so your applications have the storage they need, when they need it.

FEATURES:
- Supports the Network File System version 4(NSFv4) protocol

- You ONLY PAY for the STORAGE YOU USE

- can SCALE up to the PETABYTES

- can SUPPORT thousands of CONCURRENT NFS connection

- Data is STORED ACROSS multiples AZ's within a region

- Read After Write consistency

- BLOCK-BASED Storage not Object-based Storage


*** Amazon FSx for Windows & Amazon FSx for Lustre ***
Amazon FSx for Windows - Basically provides fully managed native Microsoft Windows File System so you can easily move your Windows-based application that requires files storage to AWS. Amazon FSx is built on Windows Server.

How is Windows FSx different to EFS?
Windows:
- A managed windows server that runs Windows Server Message Block(SMB)-based files server.
- Designed for Windows and Windows applications.
- Supports AD users, access control lists, groups and security policies along with Distributed File System (DFS) namespaces and replication.
EFS:
- A managed NAS(Network Attached Storage) file for EC2 instances based on Network File System (NFS) version 4.
- One of the first network file sharing protocols native to Unix and Linux

Amazon FSx for Lustre - is a fully managed file system that is optimized for compute-intensive workloads, such as high-performance computing, machine learning, media data process workflows, and electronic design automation (EDA).
- With Amazon FSx, you can launch and run a Lustre file system that can process massive data sets at up to hundreds of gigabytes per second of throughput, millions of IOPS, and sub-millisecond latencies.

Exam Tips:
- EFS - When you need distributed, high resilient storage for Linux instances and Linux-based applications.
- Amazon FSx for Windows - When you need centralized storage for Windows -based applications such as Sharepoint, Microsoft SQL Server, Workspaces, IIS Web Server or any other native Microsoft Application.
- Amazon FSx for Lustre - When you need high-speed, high-capacity distributed storage. This will be for applications that do High Performance Compute (HPC), financial modelling etc. Remember that FSx for Lustre can store data directly to S3.




*** What is Lambda ***

- Encapsulating the following
   = Data Centers
   = Hardware
   = Assembly Code/Protocols
   = High Level Languages
   = Operating Systems
   = Application Layer/AWS APIs

- is a compute service where you can UPLOAD your CODE and CREATE a Lambda function
- takes care of PROVISIONING and MANAGING the server that you use to run the code
- you don't have to worry about OS, patching and scaling

*** Lambda - Exam Tips ***

- Lambda SCALE Out not up automatically
- Lambda functions are independent , 1 event = 1 function
- Lambda is serverless
- Lamba functions if function can trigger orther lambda functions, 1 event can = x


   ----------------------------------
       ROUTE 53 (AWS DNS)
   ---------------------------------

Domain Registrars
- Authority that can assign domain names directly under one or more top level domains.
- Each domain name becomes registered in a central database known as WHOIS database

Start of Authority (SOA) - The SOA record stores information about:
- The name of the server that supplied the data for zone
- The administrator of the zone
- The current version of the data file
- The default number of seconds for the time-to-live file on resource recorrds

NS stands for Name Server records
- They are used by Top Level Domain servers to direct traffic to the Content DNS server which contains the authoritative DNS records.

Alias Records - same sa CNAME record
- are used to map resource sets in your hosted zone to Elastic Load Balancers, Cloudfront distribution, or S3 buckets that are configured as websites.
- Alias records work like a CNAME record in that you map on DNS name (www.example.com) to another target DNS name

What is an TTL?
- The length that a DNS record is cached on either the Resolving Server or the users own local PC is equal to the value of the "Time to live" in seconds.
- The lower the time to live, the faster changes to DNS records take to propagate throughout the internet

Alias Records
- Key difference - A CNAME can't be used for naked domain names (zone apex record)
- You can't have  a CNAME for http://acloud.guru, it must be either an A record or alias


*** Route 53 Routing Policies *** 2020

- Simple - DEFAULT ROUTING policy when you create a new record set.  This is most commonly used when you have a SINGLE SOURCE that performs a given function for your domain
	-     You can only have one record with multiple IP addresses. If you specify multiple values in a record. Route 53 returns all values to the user in random order
- Weighted - let you SPLIT traffic based on different weights assigned
- Latency - allows you to route traffic based on LOWEST NETWORK LATENCY for your end-user (which region give them the FASTEST RESPONSE TIME)
- Failover - if you want to create an active/passive setup. It MONITORS THE HEALTH OF PRIMARY SITE using health check. If health check fails, it is going to send all traffic to secondary site.
- Geolocation - let you route traffic depending on the GEOGRAPHIC LOCATION of the users (location from which DNS queries originate)
- Geoproximity Routing (Traffic Flow only) - a simple routing policy with health check. To use geoproximity routing, you must use Route 53 traffic flow.
	- You can optionally choose to route more traffic or less to a given resource by specifying a value, known as bias. A bias expands or shrinks the size of geographic region from which traffic is routed to a resource.
	- Based on Latitude and Longitude 
- Multivalue Answer Policy - Multivalue answer routing lets you configure Amazon Route 53 to return to multiple values, such as IP address for your web servers
	- You can specify multiple values for almost any record but multivalue answer routing also lets you check the health of each resource so Route 53 returns only values for healthy resources
	- Similar to Simple Routing however it allows you to put health checks on each record set

*** EXAM TIPS *** 2020

- ELB's DO NOT have pre-defined IPv4 addresses;  you resolve to them using a DNS name.

- Understand the difference between ALIAS record and CNAME
   = ALIAS records allows you to resolve naked domain name(zone apex record) to an ELB's DNS address
   = AWS CHARGE you if you request to Route 53 for DNS record using CNAME
   = Using ALIAS, you won't be charged
   = Give the choice, always choose an ALIAS record over a CNAME

*** Simple Routing Policy Exam Tips*** 2019
- If you choose the simple routing policy you can only have one record with multiple IP addresses. If you specify multiple values in a record, Route 53 returns all values to the user in random order

*** Health Checks Exam Tips*** 2019
- You can set health checks on individual record sets
- If a record set fails a health check it will be removed from Route53 until it passes the health check
- You can set SNS notifications to alert you if a health check is failed



   -------------------------------
       DATABASES ON AWS - 2020
   -------------------------------

*** Relational Database Types ***

- SQL Server
- Oracle
- MySQL Server
- PostgreSQL
- Aurora
- MariaDB

RDS has two key features:
1. Multi-AZ = For Disaster Recovery
2. Read Replicas = For performance



*** Non Relational Database ***

- Database
   = Collection    ->    Table
   = Document    ->    Row
   = Key Value Pairs ->    Fields



*** What is Data Warehousing ***

- Uses for business intelligence. Tools like Cognos, Jaspersoft, SQL Server Reporting Services, Oracle, Hyperion, SAP NetWeaver.

- Used to pull in very large and complex data sets. Usually used by management to do queries on data (such as current performance vs targets)


*** AWS Database Type ***

- RDS - OLTP (Online Transaction Processing) - pull up row of data
   = SQL
   = Oracle
   = MySQL
   = PostgreSQL
   = Aurora
   = Maria DB

- DynamoDB - No SQL

- Redshift - OLAP (Online Analytics Processing) - pulls in large numbers of records. For Business Intelligence or Data Warehousing
Example:
    Sum of Radios Sold in EMEA
    Unit Cost of Radio in each region
    Sales price of each radio

- Amazon's Data Warehouse Solution is called Redshift.

What is Elasticache?
- is a web service that makes it easy to deploy, operate and scale an in-memory cache in the cloud.
- improves the performance of web application by allowing you to retrieve information from fast, managed, in-memory caches, instead of relying
entirely on slower disk-based database
- supports two open source
1. Memcached
2. Redis
Remember the following points;
- RDS runs on virtual machine - you don't have access
- You can not login to these operating systems however.
- Patching of the RDS Operating System and DB is Amazon's responsibility
- RDS is not Serverless
- Aurora Serverless is Serverless


*** Automated Backups ***

- There are two different types of Backups for AWS: Automated Backups and   Snapshots

- Automated Backups
   = allows you to recover database to any point in time within "RETENTION PERIOD"
   = "RETENTION PERIOD" can be 1 to 35 days
   = take a FULL DAILY SNAPSHOT and will also store transaction logs throughout the day
   = first CHOOSE MOST RECENT BACKUP and apply transaction logs relevant to that day
   = allows you to do point in time recovery down to a second within the retention period
   = enabled by default
   = backup data is stored in S3. you get FREE STORAGE equal to the size of database. If you have an RDS instance of 10GB
       you will get 10GB worth of storage for FREE
   = backups are taken within a defined window
   = during backup window, STORAGE I/O MAY BE SUSPENDED while your data is being backed up and may EXPERIENCE ELEVATED LATENCY

- Snapshots
   = done manually (user initiated)
   = stored even after the original RDS instance is deleted UNLIKE AUTOMATED BACKUPS

*** Restoring Backups ***

- Whenever you restore either Automatic Backup or manual manual Snapshot, the RESTORED VERSION of the database
   will be a NEW RDS INSTANCE WITH A NEW DNS ENDPOINT.

original.eu-west-1.rds.amazonaws.com ----> restored.eu-west-1.rds.amazonaws.com

*** Encryption ***

- Encryption AT REST is supported for MySQL, Oracle, SQL Server, PostgreSQL, Aurora.
- Encryption is done using the AWS Key Management Service (KMS)
- Once your RDS INSTANCE IS ENCRYPTED, the DATA STORED AT REST in the underlying storage is ENCRYPTED as are all of its
   automated backups, read replicas and snapshots
- At the present time, ENCRYPTION an EXISTING DB INSTANCE is not SUPPORTED.
- To use AMAZON RDS ENCRYPTION for an existing database, first CREATE A SNAPSHOT, MAKE A COPY of that SNAPSHOT, and ENCRYPT
   THE COPY

*** What is Multi-AZ RDS? ***

- Multi-AZ allows you to have an EXACT COPY of your production DATABASE in ANOTHER AVAILABILITY ZONE
- AWS handles the replication for you, so when the production DATABASE is WRITTEN TO, this will
   AUTOMATICALLY be SYNCHRONIZED to the stand by database
- In the event of PLANNED DATABASE MAINTENANCE, DB INSTANCE FAILURE, or AN AVAILABILITY ZONE FAILURE,
   AMAZON RDS will AUTOMATICALLY FAILOVER to the standby so that database operations can resume
   quickly

- For DISASTER RECOVERY only. It is NOT primarily used for IMPROVING PERFORMANCE.
- For PERFORMANCE IMPROVEMENT, you need REPLICAS
- Available to all Relational Database Types


*** What is a Read Replica? ***

- Allows you to have a read-only copy of your production database.
- This is achieved by USING ASYNCHRONOUS REPLICATION from the PRIMARY RDS instance to read replica
- You used READ REPLICA primarily for VERY READ-HEAVY database workload
- Available to all Relational Database Types EXCEPT ORACLE AND MSSQL
- Used for SCALING NOT DISASTER RECOVERY
- Must have AUTOMATIC BACKUPS TURNED ON in order to deploy a read replica
- You can have up to 5 READ REPLICA COPIES of any database
- You can have READ REPLICAS of READ REPLICAS (watchout for LATENCY)
- Each READ REPLICA can HAVE its own DNS ENDPOINT
- You CAN have READ REPLICAS that HAVE MULTI-AZ (new feature in Jan 2018)
- You CAN create READ REPLICAS of MULTI-AZ source databases
- Read Replicas CAN be PROMOTED to be their own Databases. This BREAKS the REPLICATION.
- You CAN have a Read Replica in a SECOND REGION

Things to know about Read Replicas;
- Used for scaling, not DR!
- Must have automatic backups turned on in order to deploy read replica.
- You can have up to 5 read replica copies of any database
- You can read replicas of read replicas (but watch out for latency)
- Each read replica will have its own DNS end point.
- You can have read replicas that have Multi-AZ
- You can create read replicas of Multi-AZ source database
- Read Replicas can be promoted to be their own database. This breaks the replication.
- You can have a read replica in a second region.


*** What is DynamoDB? ***

- It is a FAST and FLEXIBLE NoSQL database service for all applications that need consistent, single-digit
   millisecond latency at any scale.
- It is a FULLY MANAGED DATABASE and supports both document and key-value data models.
- Its FLEXIBLE data model and RELIABLE performance make it a great FIT for mobile, web, gaming, ad-tech,
   IoT, and many other applications
- Stored on SSD Storage
- Spread across 3 geographically DISTINCT DATA CENTERS (3 Multiple AZ) (3 different facilities)
- Eventual Consistent Reads
   = CONSISTENCY across all copies of data is usually REACHED within a SECOND.
   = REPEATING a read after a short time should return an updated data (Best Read Performance)
   = if data write CAN WAIT to propagate throughout data centers
- Strongly Consistent Reads
   = a STRONGLY CONSISTENT read returns a result that reflects all writes that received a successful
   response prior to the read
   =  information IMMEDIATELY NEEDED to be available within a second or LESS
- EXPENSIVE for writes, CHEAP for reads

*** DynamoDB Pricing ***

- Provisioned Throughput Capacity
   = Write Throughput $0.00665 per hour for every 10 units
   = Read Throughput $0.00065 per hour for every 50 units
- Storage costs of $0.25 GB per month

*** What is Redshift ***

- Amazon Redshift is a FAST and POWERFUL, FULLY MANAGED, petabyte scale data WAREHOUSE SERVICE in the cloud.
- Customers CAN START SMALL for just 0.25$ per hour with no commitments or upfront costs and scall to a petabyte or more
   $1,000 per terabyte per year, LESS THAN a tenth of most other data warehousing solutions

*** OLAP ***

*** Redshift Configuration ***

- Single Node (160 GB)
- Multi Node
   = Leader Node (MANAGES client CONNECTION and RECEIVES queries)
   = Compute Node (STORE data and PERFORM queries and computations). Up to 128 Compute Nodes

*** Redshift - 10 times faster ***

- Columnar Data Storage
   = Instead of storing data as a series of ROWS, AMAZON Redshift organizes data
   by COLUMN
   = Unlike ROW-BASED systems, which are ideal for transaction processing, column-based systems
   are ideal for data warehousing and analytics, where queries often involve aggregates performed over
   large data sets
   = Since ONLY the COLUMNS involved in the queries are processed and columnar data is STORED SEQUENTIALLY on the storage
   media

- Advanced Compression
   = Columnar data STORES can be COMPRESSED much more than row-based data stores because SIMILAR data is STORED
   sequentially on disk
    = Amazon Red Shift employs multiple compression techniques and can often achieve significant compression relative to traditional relational stores.
    = Doesn't require indexes or materialized views so it uses less space
    = Selects the most appropriate compression scheme when loading data into an empty table

- Massively Parallel Processing (MPP)
   = Amazon Redshift automatically distributes data and query load across all nodes.
    = Makes it easy to add nodes to your data warehouse and enables you to maintain fast query performance as your warehouse grows.

- Redshift Backups
    = Enabled by default with a 1 day retention period
    = Maximum retention period of 35 days
    = Always attempts to maintain at least three copies of your data (the original and replica on the compute nodes and a backup in Amazon S3)
    = Can asynchronously replicate your snapshot to S3 in another region for DR.

- Redshift Pricing
    = Compute Node Hours (total number of hours you run across all your compute nodes for the billing period)
    = You will not be charged for leader node hours; only compute nodes will incur charges
    = You will be charged for Backups and Data Transfer (only within VPC, not outside it)

*** Redshift Security ***
- Encrypted IN TRANSIT using SSL
- Encrypted AT REST using AES-256 encryption
- By default Redshift takes care of key management
   = Manage your own keys through HSM (Hardware Security Module)
   = AWS Key Management Service (KMS)


*** Redshift Availability ***
- Currently only available in 1 AZ
- Can restore snapshots to new AZ's in the event of an outage

*** Redshift Exam Tips*** 2019
- Back ups is enabled by default with a 1 day retention period
- Maximum retention period is 35 days
- Redshift always attempts to maintain at least three copies of your date (the original and replica on the compute nodes and a backup in Amazon S3)
- Redshift can asynchronously replicate your snapshots to S3 in another region for disaster recovery
- Used for Business Intelligence
- Available only in 1 AZ


*** Amazon Aurora***
- Amazon's own proprietary database
- is a MySQL and PostgreSQL- compatible relational database engine that combines the speed and availability of high-end commercial databases with simplicity and cost-effectiveness of open source database
- provides up to five times better performance than MySQL and three times better than PostgreSQL databases at a much lower price point, whilst delivering similar performance and availability

Things to know about Aurora
1. Start with 10 GB, Scales in 10GB increments to 64 TB (Storage Auto Scaling)
2. Compute resources can scale up to 32vCPUs and 244 GB of memory
3. 2 copies of your data is contained in each availability zone, with minimum of 3 availability zones. 6 copies of your data

Scaling Aurora
- Aurora is designed to transparently handle the loss of up to 2 copies of data without affecting database write availability and up to 3 copies without affecting read availability
- Aurora storage is also self-healing. Data blocks and disks are continuously scanned for errors and repaired automatically.

Three Types of Aurora Replicas are available:
1. Aurora Replicas (currently 15)
2. MySQL Read Replica (currently 15)
3. PostgreSQL (currently 1)

Backups with Aurora
- Automated backups are always enabled on Amazon Aurora DB Instances. Backups do not impact database performance.
- You can also take snapshots with Aurora. This also does not impact on performance.
- You can share Aurora snapshots with other AWS accounts.

Amazon Aurora Serverless
- is an on-demand, autoscaling configuration for the MySQL-compatible and PostgreSQL-compatible editions of Amazon Aurora.
- An Aurora Serverless DB Cluster automatically starts up, shuts down and scales capacity up or down based on your application needs.
- provides a relatively simple, cost-effective option for infrequent, intermittent or unpredictable workloads
- Incurring cost only when someone access your website



*** Aurora Exam Tips *** 2020

- 2 copies of your data is contained in each availability zones, with minimum of 3 availability zones. 6 copies of your data
- You can share Aurora Snapshots with other AWS accounts
- 3 types of replicas available. Aurora Replicas, MySql Replicas and PostgreSQL Replicas . Automated failover is only available with Aurora Replicas
- Aurora has automated backups turned on by default. You can also take the Snapshots with Aurora. You can share these Snapshots with other AWS accounts
- provides a relatively simple, cost-effective option for infrequent, intermittent or unpredictable workloads

*** Elasticache ***
- is a web service that makes it easy to deploy, operate and scale in-memory cache in cloud.
- The service improves performance of web applications by allowing you to retrieve information from fast, managed, in-memory caches, instead of relying entirely on slower disk-based database.
- cache most frequent information

Memcached vs Redis

*** Elasticache Exam Tips *** 2019
- Use Elasticache to increase database and web application performance
- Redis is Multi-AZ
- You can do backups and restores of Redis
- If you need to scale horizontally, use Memcached.


*** Remember the following points *** 2019

- RDS runs on virtual machines
- You cannot log in to these operating systems however
- Patching of the RDS Operating System and DB is Amazon's responsibility
- RDS is not Serverless
- Aurora Serverless IS Serverless


*** Read Replicas Exam Tips*** 2019

- Can be Multi AZ
- Used to increase performance
- Must have backups turned on
- Can be in different regions
- Can be Aurora or MySQL
- Can be promoted to master, this will break the replication with the Read Replica

*** Multi AZ Exam Tips *** 2019

- Used for DR(Disaster Recovery)
- You can force a failover from one AZ to another by rebooting the RDS instance
- Can be Aurora or MySQL   

Add tips:
- Encryption at rest is supported for MySQL, Oracle, SQL Server, PostgreSQL, MariaDB and Aurora. Encryption is done using the AWS Key Management Service(KMS). Once your RDS instance is encrypted, the data stored at rest in the underlying storage is encrypted, as are its automated backups, read replicas and snapshots

*** Dynamo DB Exam Tips *** 2019

- Stored on SSD Storage   
- Spread across 3 geographically distinct data centres
- Eventual consistent reads (default) = if the application does not need to read the updated data within 1 sec
- Strongly consistent reads = if the application needs to have a complete copy of data in less than 1 sec

*** Red Shift Exam Tips*** 2019

- Enabled by default with a 1 day retention period
- Maximum retention period is 35 days
- Redshift always attempts to maintain at least three copies of your data (the original and replica on the compute nodes and a backup in Amazon S3)
- Redshift can also asynchronously replicate your snapshot to S3 in another region for Disaster Recovery



   -------------------------------
                    VPC - 2020
   -------------------------------

- Virtual Data Center in the cloud
- lets you PROVISION a logically ISOLATED SECTION of the Amazon web services Cloud where you can launch AWS resources
- you have complete control over your virtual networking environment, including Ip address range, creation of subnets and configuration of
   route tables and network gateways
- you can create PUBLIC-FACING subnet and PRIVATE-FACING subnet with no internet access.
- you can LEVERAGE MULTIPLE LAYERS of SECURITY, including security group and network access control list
- you can CREATE a HARDWARE VIRTUAL PRIVATE NETWORK (VPN) connection between your corporate datacenter and your VPC and leverage the AWS
   cloud as an extension of your corporate datacenter
- you can have maximum of 5 VPC

*** VPC Exam Tips *** 2019

- think of a VPC as a logical datacenter in AWS
- consists of IGWs or (Virtual Private Gateways), Route tables, Network Access Control Lists, Subnet and Security Groups
- 1 Subnet = 1 Availability Zone
- Security Groups are Stateful; Network Access Control Lists are Stateless
- NO TRANSITIVE PEERING

- When you create a VPC a default Route Table, NACL and Security Group are also created
- It won't create any subnets, nor will it create a default Internet Gateway
- US-East-1a in your AWS account can be completely different availability zone to US-East-1a in another AWS account. The AZ's are randomized
- Amazon always reserve 5 IP addresses within your subnets
- You can only have 1 Internet Gateway per VPS
- Security Group can't span VPCs.


*** Different Internal IP range ***

10.0.0.0 - (10/8 prefix)
172.16.0.0 - (172.16/12 prefix)
192.168.0.0 - (192.168/16 prefix)

*** What can you do with a VPC ***

- LAUNCH INSTANCE into a SUBNET of your choosing
- ASSIGN CUSTOM IP address ranges
- CONFIGURE ROUTE TABLES between subnets
- Create INTERNET GATEWAY and attach it to our VPC
- Much better SECURITY CONTROL over your AWS resources
- Instance SECURITY GROUP
- Subnet network ACCESS CONTROL LISTS (ACLS)

*** Default VPC vs Custom VPC *** 2020

- Default VPC is user friendly, allowing you to IMMEDIATELY DEPLOY instances
- ALL SUBNETS in default VPC have a ROUTE OUT to the internet
- Each EC2 has both a public and private IP address

*** VPC Peering *** 2020

- allows you to CONNECT one VPC with ANOTHER via a direct network route using private IP addresses
- Instances BEHAVE as if they were on the SAME PRIVATE NETWORK
- You CAN peer VPC's with other AWS accounts as well as with other VPC's in the same account
- Peering is in a star configuration: ie 1 central VPC peers with 4 others. NO TRANSITIVE PEERING!!!


*** Exam Tips - NAT Instance*** 2020

- When creating a NAT INSTANCE, disable SOURCE/DESTINATION check on the instance
- NAT isntances MUST be in a PUBLIC subnet
- There MUST be a ROUTE OUT of the private subnet to the NAT instance, in order for this to work
- The amount of TRAFFIC that NAT instances CAN SUPPORT depends on the instance size. If you are bottlnecking, increase the instance size
- You CAN CREATE high availability using Autoscaling Groups, multiple subnets in different AZs, and a script to automate failover
- BEHIND a Security Group

*** Exam Tips - NAT Gateways *** 2020
- Redundant inside the Availability Zones
- Preferred by the enterprise
- Starts at 5 Gbps and scales currently to 45 Gbps
- No need to patch
- NOT ASSOCIATED with security groups
- Automatically assigned a public ip address
- Remember to update your route tables (to point to NAT Gateway)
- It is advisable to HAVE NAT GATEWAY on another AZ to have some form of redundancy in case of failure
- NO NEED to disable Source/Destination check
- More SECURE than a NAT Instance
- If you have resources in multiple Availability Zones and they share one  NAT gateway, in the event that the NAT gateway's Availability zone is down, resources in the other Availability zones lose internet access. To create an Availability Zone- independent architecture, create a NAT gateway in each Availability Zone and configure your routing to ensure resources use the NAT gateway in the same availability Zone.



*** 5 Reserved IP addresses ***


*** Network Access Control List (NACL) Exam Tips ***

- Your VPC AUTOMATICALLY COMES a default network ACL and by default it allows all outbound and inbound traffic
- You can create custom network ACLs. By default, each custom network ACL denies all inbound and outbound traffic until you add rules
- Each subnet MUST be associated with a network ACL. If you DONT EXPLICITLY associate a subnet with a network ACL, the subnet is automatically
   associated with a DEFAULT network ACL
- You can associate a network ACL with multiple subnets: however, a subnet can be associated with only one network ACL at a time. When you associate
   a network ACL with a subnet, the PREVIOUS association is REMOVED.
- Network ACLs contain a numbered list of rules that is EVALUATED IN ORDER, starting with the lowest numbered rule
- Network ACLs have SEPARATE INBOUND AND OUTBOUND RULE, and each rule can either allow or deny
- Network ACLS are STATELESS; responses to allow inbound traffic are subject to the rules for outbound traffic (vice versa)
- Block IP addresses using network ACLs not Security Group

*** VPC Flow Logs ***

- is a feature that enables you to CAPTURE INFORMATION ABOUT THE IP TRAFFIC going to and from the network interfaces in your VPC. Flow log data is
   STORED using Amazon Cloudwatch Logs. After you've created a flow log, you CAN VIEW and RETRIEVE its data in Amazon Cloudwatch Logs
- You CANNOT enable flow logs for VPCs that are PEERED with your VPC unless the peer VPS is in your account. Have to be in the same account
- You CANNOT tag a flow log
- After you've created a flow log, you cannot change its configuration: for example you can't associate a different IAM role with the flow log

- NOT ALL traffic is monitored;
   = Traffic GENERATED by INSTANCES when they contact the Amazon DNS server. If you use your OWN DNS server, then ALL TRAFFIC to that DNS
       server is LOGGED
   = Traffic GENERATED by Windows instance for Amazon Windows license activation
   = Traffic to and from 169.254.169.254 for INSTANCE METADATA
   = DHCP Traffic
   = Traffic to the RESERVED IP address for the default VPC ROUTER

VPC Flow logs Level
- VPC
- Subnet
- Network Interface Level

*** What is a Bastion Host? ***
- is a special purpose computer on network specifically designed and configured to withstand attacks.
- The computer generally hosts a single application, for example proxy server, and all other services are removed or limited to reduce the threat to the computer.
- It is hardened in this manner primarily due to its location and purpose, which is either on the outside of a firewall or in a demilitarized zone (DMZ) and usually involves access from untrusted networks or computers
- way of SSHing private instance in private subnet

*** Exam Tips - NAT vs Bastions ***

- A NAT Gateway or NAT Instance is used to PROVIDE INTERNET TRAFFIC to EC2 instances in private subnets
- A Bastions is used to SECURELY ADMINISTER EC2 instances (using SSH or RDP) in private subnets. Bastions are called Jumb Boxes in Australia.


*** What is Direct Connect? ***
- AWS Direct Connect is a cloud service solution that makes it easy to establish a dedicated network connection from your premises to AWS.
- Reduce network costs, increase bandwidth throughput, and provide a more consistent network experience that Internet-based connection

*** Exam Tips - Direct Connect ***
- Direct Connects directly connects your data center to AWS
- Useful for high network throughput workload (ie lots of network traffic)
- Or if you need a stable and reliable secure connection

Setting UP Direct Connect - Steps (IMPORTANT)
1. Create a Virtual interface in the Direct Connect console. This is a PUBLIC Virtual Interface
2. Go to VPC console and then to VPN connections. Create Customer Gateway
3. Create a Virtual Private Gateway
4. Attach the Virtual Private Gateway to the desired VPC
5. Select VPN connections and create a new VPN connections
6. Select the Virtual Private Gateway and the Customer Gateway
7. Once the VPN is available, setup the VPN on the customer gateway or firewall
Reference: https://www.youtube.com/watch?v=dhpTTT6V1So&feature=youtu.be

*** What is AWS Global Accelerator? ***
- is a service in which you create accelerators to improve availability and performance of your applications for local and global users.
- Global accelerator directs traffic to optimal endpoints over the AWS global network.
- This improves the availability and performance of your internet applications that are used by a global audience
- By default, Global Accelerator provides you with two static IP addresses that you associate with your accelerator.

AWS Global Accelerator Includes the following components:
- Static IP addresses
- Accelerator
- DNS Name
- Network Zone
- Listener
- Endpoint Group
- Endpoint

*** Exam Tips - Global Accelerator ***
- is a service in which you create accelerators to improve availability and performance of your applications for local and global users
- You are assigned two static IP Addresses (or alternatively you can bring your own)
- You can control traffic using traffic dials. This is down within the endpoint group

*** What is VPC Endpoints? ***
- enables you to privately connect your VPS to supported AWS services and VPC endpoints services powered by PrivateLink without requiring an internet gateway, NAT device, VPN connections, or AWS Direct Connect connection.
- Instances in your VPC do not require public IP Address to communicate with resources in the service.
- Traffic between your VPC and the other service does not leave the Amazon network
- Endpoints are virtual devices. They are horizontally scaled, redundant, and highly available VPC components that allow communication between instances in your VPC and services without imposing availability risks or bandwidth constraints on your network traffic

There are two types of VPC endpoints
- Interface endpoints
	- is an elastic network interface with a private IP address that serves as an entry point for traffic destined to a supported device.
	- ENI is attached to an EC2 instance to establish so there's no need to traverse internet
- Gateway endpoints - currently gateway endpoints support:
	- Amazon S3
	- DynamoDB

   -------------------------------
        HA ARCHITECTURE - 2020
   -------------------------------
*** What is a Load Balancer? ***

Load Balancer Types:
- Application Load Balancer
	- are best suited for load balancing of HTTP and HTTPS traffic. They operate at Layer 7 and are application-aware.
	- They are intelligent, and you can create advanced request routing, sending specified requests to specific web servers.
- Network Load Balancer
	- are best suited for load balancing of TCP traffic where extreme performance is required. Operating at the connection level (Layer 4).
	- Network Load Balancer are capable of handling million of requests per second, while maintaining ultra-low latencies.
	- Use for extreme performance!
- Classic Load Balancer
	- are the legacy Elastic Load Balancers. You can load balance HTTP/HTTPS applications and use Layer 7- specific features, such as X-Forwarded and sticky sessions.
	- You can also use strict Layer 4 load balancing for application that rely purely on the TCP protocol.
	- X-Forwarded for contains the public IP address of the requester/user
	- Keep the cost down. No intelligence built in

*** Exam Tips - Load Balancer ***
- 504 Error means the Gateway has timed out. This means that the application not responding within the idle timeout period.
- Troubleshoot the application. Is it the Web Server or Database Server?
- If you need the IPv4 address of your end user, look for the X-Forwarded header
- Instances monitored by ELB are reported as; InService, or OutofService
- HealthChecks check the instance health by talking to it
- Load Balances have their own DNS name. You are never given an IP address.
- Read the ELB FAQ for Classic Load Balancers

*** Advanced Load Balancer Theory ***
- Sticky Sessions
	- Classic Load Balancer routes each request independently to the registered EC2 instance with the smallest load.
	- Allows you to bind user's session to a specific EC2 instance. This ensures that all requests from the user during the session are sent to the same instance.
	- You can enable Sticky Sessions for Application Load Balancer as well, but the traffic will be sent at the Target Group Level rather than individual EC2 instance
- No Cross Zone Load Balancing
	- Sending traffic across all instances of different AZ evenly
	- enables you to load balance across multiple availability zones
- Path Patterns
	- You can create a listener with rules to forward requests based on the URL path. This is known as path-based routing.
	- If you are running microservices, you can route traffic to multiple back-end services using path-based routing.
	- For example, you can route general request to one target group and requests to render images to another target group
	- allows you to direct traffic to different EC2 instances based on the URL contained in the request

    *** Auto Scaling ***
Auto Scaling has 3 components:
1. Groups
	- Logical Component. Web Server group or Application group or Database group
2. Configuration Templates
	- Groups uses a launch template or a launch configuration as a configuration template for its EC2 instances.
	- You can specify information such as the AMI ID, instance type, key pair , security groups, and block device mapping of your instances
3. Scaling Options
	- provides several ways for you to scale your Auto Scaling groups. For example, you can configure a group to scale based on the occurrence of specified conditions (dynamic scaling) or on a schedule

What are my scaling options?
- Maintain current instance levels at all times
	- To maintain the current instance levels, Amazon EC2 Auto Scaling performs  a periodic health check on running instance
	- When Amazon EC2 Auto Scaling finds an unhealthy instance, it terminates that instance and launches a new one.
- Scale manually
	- Most basic way to scale your resources, where you specify only the change in the maximum, minimum, or desired capacity of your Auto Scaling group
	- Amazon EC2 Auto Scaling manages the process of creating and terminating instances to maintain the updated capacity
- Scale based on a schedule
	- Scaling by schedule means that scaling actions are performed automatically as a function of time and date
	- This is useful when you know exactly when to increase or decrease the number of instances in your group, simply because the need arises on a predictable schedule
- Scale based on demand
	- A more advanced way to scale your resources - using scaling policies - lets you define parameters that control the scaling process
	- Useful for scaling in response to changing conditions, when you don't know when those conditions will change.
- Use predictive scaling
	- helps you maintain optimal availability and performance by combining predictive scaling and dynamic scaling (proactive and reactive approaches respectively)
	- Predicting based on your previous performance

Everything fails. Everything.
You should always plan for failure.

Remember the following:
- Always design for failure
- Use Multiple AZ's and multiple region wherever you can
- Know the difference between Multi-AZ and Read Replicas for RDS
- Know the difference between scaling out and scaling up
- Read the question carefully and always consider the cost element
- Know the different s3 storage classes

*** Exam Tips - CloudFormation ***
- Is a way of completely scripting your cloud environment
- Quick Start is a bunch of CloudFormation templates built by AWS Solutions Architects allowing you to create complex environments quickly

*** Elastic Beanstalk ***
- You can quickly deploy and manage applications in the AWS Cloud without worrying about the infrastructure that runs those applications.
- You simply upload your applications, and Elastic Beanstalk automatically handles the details of capacity provisioning, load balancing, scaling, and application health monitoring.


   -------------------------------
        APPLICATION SERVICES - 2020
   -------------------------------

*** SQS (Simple Queue Service) ***
- is a web service that gives you ACCESS to a MESSAGE QUEUE that can be USED TO STORE MESSAGES while waiting for a computer to process them
- is a DISTRIBUTED QUEUE SYSTEM that enables web service application to QUICKLY and reliably QUEUE MESSAGES that one component in the APPLICATION
   GENERATES to be CONSUMED by another component
- is a TEMPORARY REPOSITORY for messages that awaiting processing

*** What is SQS ***
- can DECOUPLE the COMPONENTS for an application so they run independently
- any COMPONENT can later RETRIEVE the messages PROGRAMMATICALLY using the Amazon SQS API
- the queue acts as a BUFFER the component producing and saving data and the component receiving the data for processing.
- this means the queue RESOLVES tissues that arise if the producer is PRODUCING work faster than the consumer CAN PROCESS it, or if the producer
   or consumer are only intermittently connected to the network

*** Queue Types ***

- Standard Queue (default)
   = lets you have a NEARLY-UNLIMITED number of transaction per second.
   = GUARANTEED that a message is DELIVERED at least once
   = because of HIGHLY-DISTRIBUTED ARCHITECTURE that allows high throughput, more than one copy of a message might be delivered
   = provide BEST-EFFORT ordering which ensures that messages are generally delivered in the same order as they are sent
   
- FIFO Queues
   = COMPLEMENTS that standard queue
   = SENT and RECEIVED is strictly PRESERVED
   = a message is delivered once and remains available until a consumer processes and deletes it
   = duplicates are NOT INTRODUCED into the queue.
   = supports MESSAGE GROUP that allow limited to 300 transaction per second, but have all the capabilities of standard queue

*** Exam Tips - SQS *** Not much in the exam
- SQS is pull-based, not pushed-based
- Messages are 256 KB in size
- Messages can be kept in the queue from 1 minute to 14 days; the default retention period is 4 days.
- Visibility timeout is the amount of time that the message is invisible in the SQS queue after a reader picks up that message.
  Provided that the job is processed before visibility timeout expires, the message will then be deleted from the queue.If the job is not processed within that time, the message will become visible again and another reader will process it. This could result in the same message being delivered twice
- Visibility timeout maximum is 12 hours
- SQS guarantees that your messages will be processed at least once.
- Amazon SQS long polling is a way to retrieve messages from your Amazon SQS queues. While the regular short polling returns immediately (even if the message being queued is empty ), long polling doesn't return response until a message arrives in the message queue, or the long poll times out.
- Any time you see a scenario based questions about "decoupling" your infrastructure - think SQS

*** Simple Work Flow Service (SWF) ***
- is a web service that makes it easy to coordinate work across distributed application components.
- SWF enables applications for a range of use cases, including media processing, web application back-ends, business process workflow and analytics pipelines, to be designed as a coordination of tasks.
- Tasks represent invocations of various processing steps in an application which can be performed by executable code, web service calls, human actions, and script
  

*** Exam Tips - SWF vs SQS ***
- SQS has a retention period of 14 days; with SWF, workflow executions can last up to 1 year
- Amazon SWF presents a task-oriented API, whereas Amazon SQS offers a message-oriented API
- Amazon SWF ensures that a task is assigned only once and is never duplicated. With Amazon SQS, you need to handle duplicated messages and may also need to ensure that a message is processed only once.
- Amazon SWF keeps track of all the tasks and events in an application. With Amazon SQS, you need to implement your own application-level tracking, especially if your application uses multiple queues.
SWF Actors 
- Workflow Starters - an application that initiates a workflow
- Deciders - control the flow of workflow execution. Decides what to do next
- Activity Workers - Carry out activity tasks

*** Simple Notification Service (SNS) ***
- is a web service that makes it easy to setup, operate and send notifications from cloud.
  

*** Exam Tips - SNS ***
- Instantaneous, push-based delivery (no polling)
- Simple APIs and easy integration with applications
- Flexible message delivery over multiple transport protocols

*** SNS vs SQS ***
- Both messaging Services in AWS
- SNS - Push
- SQS - Polls (Pulls)

*** Elastic Transcoder *** Not much in the exam 2020
- Media Transcoder in the cloud
- Convert media files from their original source format in to different formats that will play on smart phones, tablets, PC and etc
- Provides transcoding presets for popular output formats, which means that you don't need to guess about which settings work best on particular devices
- Pay based on the minutes that you transcode and the resolution at which you transcode

*** API Gateway ***
- Amazon API Gateway is a fully managed service that makes it easy for developers to publish, maintain, monitor, and secure APIs at any scale
- You can create an API that acts as a "front door" for applications to access data, business logic or functionality
  


What can API Gateway do?
- Expose HTTPS endpoints to define a RESTful API
- Serverless-ly connect to services like Lambda & DynamoDB
- Send each API endpoint to a different target
- Run efficiently with low cost
- Scale effortlessly
- Track and control usage by API key
- Connect to CloudWatch to log all requests for monitoring
- Maintain multiple versions of your API
  


API Gateway Caching
- You can enable API caching in Amazon API Gateway to cache endpoint's response. With caching, you can reduce the number of calls made to your endpoint and also improve the latency of the requests to your API
- API Gateway caches responses from your endpoint for a specified time-to-live (TTL) period, in seconds. API Gateway responds to request by looking up the endpoint response from the cache instead of making a request to your endpoint.

Same Origin Policy
- In computing, same-origin policy is an important concept in the web application security model.
- Under the policy, a web browser permits scripts contained in a first web page to access data in a second web page but only if both pages have the same origin
- This is done to prevent Cross-Site Scripting (XSS) attacks
  Enforced by web browsersIgnored by tools like Postman and Curl
  
CORS explained
- is one way the server at the other end (not the client code in the browser) can relax the same-origin policy
- Cross-origin resource sharing (CORS) is a mechanism that allows restricted resources on a web page to be requested from another domain outside domain from which the first resource was served
CORS in action
- Error - "Origin policy cannot be read at the remote resource?". You need to enable CORS on API Gateway
API Gateway Exam Tips:
- Remember what API Gateway is at a high level
- API Gateway has caching capabilities to increase performance
- API Gateway is low cost and scales automatically
- You can throttle API Gateway to prevent attacks
- You can log results to CloudWatch
- If you are using Javascript/AJAX that uses multiple domains with API Gateway, ensure that you have enabled CORS on API Gateway
- CORS is enforced by the client (browser)

*** Kinesis ***
- is a platform on AWS to send your streaming data to
- makes it easy to load and analyze streaming data and also providing the ability for you to build your own custom applications for your business needs
What is a streaming data?
- is a data that is generated continuously by thousands of data sources, which typically send in the data records simultaneously and in small sizes.
  Purchases from online stores (think amazon.com)Stock PricesGame data ( as the gamer plays)Social network dataGeospatial data (think uber.com)iOT sensor data
3 Different Types of Kinesis
- Kinesis Streams
  has shards which stores data persistently for maximum of 7 days
- Kinesis Firehose
  Analyze data on the fly using Lambda
- Kinesis Analytics
	- Analyze data inside Kinesis Streams/Firehose

*** Web Identity Federation & Incognito ***
- Lets you give your user access to AWS resources after they have successfully authenticated with a web-based identity provider like Amazon, Facebook or Google
- Following successful authentication, the user receives an authentication code from Web ID provider, which they can trade for temporary AWS security credentials.
Amazon Incognito
- Amazon Incognito provides Web Identity Federation with the ff features:
  Sign-up and sign-in to your appsAccess for guest usersActs as an Identity broker between your application and Web ID providers, so you don't need to write any additional codeSynchronizes user data for multiple deviceRecommended for all mobile applications AWS service
Cognito User Pools
- User pools are user directories used to manage sign-up and sign-in functionality for mobile and web applications
- User can sign-in directly to the User Pool, or using Facebook, Amazon or Google.
  
- Cognito acts as an Identity Broker between the identity provider and AWS.
- Successful authentication generates a JSON Web Token (JWTs)
- all about username and password
Cognito Identity Pools
- Identity Pools enable provide temporary AWS credentials to access AWS services like S3 or DynamoDB
- granting of access to AWS resources
Cognito Synchronization
- Cognito tracks the association between user identity and the various different devices they sign-in from.
- In order to provide a seamless user experience for your application, Cognito uses Push Synchronization to push updates and synchronize user data across multiple devices.
- Cognito uses SNS to send a notification to all the devices associated with a given user identity whenever data stored in the cloud changes
** Cognito Exam Tips ***
- Federation allows users to authenticate with a Web Identity Provider (Facebook, Google, Amazon)
- The user authenticates first with Web ID Provider and receives an authentication token, which is exchanged for temporary AWS credentials allowing them to assume an IAM role
- Cognito is an Identity Broker which handles interaction between your applications and the Web ID provider
- User pool is user-based. It handles things like user registration, authentication and account recovery
- Identity pools authorize access to your AWS resources

   -------------------------------
        SECURITY - 2020
   -------------------------------
Reducing Security Threats
- Bad Actors
  Typically automated processesContent scrapersBad botsFake User AgentDenial of Service (Dos)Reduce security threatsLower overall costs
  
CloudHSM (Cloud Hardware Security Modules)
- Dedicated hardware security module (HSM)
- FIPS 140-2 Level 3 (Compliance Level)
- Level 2 is KMS
- Manage your own keys - difference with KMS
- No access to the AWS-managed component
- Runs within a VPC in your account
- Single tenant, dedicate hardware, multi-AZ cluster
- Industry-standard APIs - no AWS APIs
- PKCS#11
- Java Cryptography Extensions
- Microsoft CryptoNG (CNG)
- Keep your keys safe - irretrievable if lost

  -------------------------------
        SERVERLESS - 2020
   -------------------------------

*** What is a Lambda***
- is a compute service where you can upload your code and create a lambda function.
- AWS Lambda takes care of provisioning and managing the servers that you use to run the code.
- You don't have to worry about the operating system, patching, scaling

You can use  Lambda in the following ways;
- An an event-driven compute service where AWS Lambda runs your code in response to events. These events could be changes to data in an Amazon S3 bucket or Amazon DynamoDB table
- As a compute service to run your code in response to HTTP requests using Amazon API Gateway or API calls made using AWS SDKs. This is what Cloudguru uses.

What Language does lambda support?
- Nodes.js
- Java
- Python
- C#
- Go
- Powershell

How is Lambda Priced?
- Number of requests
  first 1 million requests are free
- Duration
  Duration is calculated from the time your code begins executing until it returns or otherwise terminates, rounded up to the nearest 100ms.The price depends on the amount of memory you allocate to your functionYou are charged $0.00001667 for every GB-second used
  
Lambda Exam Tips
- Lambda scales out (not up) automatically
- Lambda functions are independent, 1 event = 1 function
- Lambda is serverless
- Know what services are serverless
- Lambda functions can trigger other lambda functions, 1 event can = x functions if functions trigger other function
- Architecture can get extremely complicated, AWS X-ray allows you to debug what is happening
- Lambda can do things globally, you can use it to back up S3 buckets to other S3 buckets etc
- Know your triggers

What can trigger Lambda
- API Gateway
- AWS IoT
- Application Load Balancer
- CloudWatch Events
- CloudWatch Logs
- CodeCommit
- Cognito Sync Trigger
- DynamoDB
- Kinesis
- S3
- SNS
- SQS


2020

Exam Tips:
3 Different ways to share s3 buckets across accounts
- Using Bucket Policies & IAM (applies across the entire bucket). Programmatic Access only
- Using Bucket ACLs &IAM (individual objects). Programmatic Access only
- Cross account IAM Roles. Programmatic and Console access